{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/stroke.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.981959\n",
       "1    0.018041\n",
       "Name: stroke, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'stroke'\n",
    "df[label].value_counts()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The balance of data is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'id' identifies unique individual. It is not a contributing factor to stroke. So I will drop the 'id' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0)/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains missing values in 'bmi' and 'smoking_status'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People who do not fill in 'smoking_status' information may have similar reasons why they don't. So I will replace the missing values in 'smoking_status' with 'missing' as a separate category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'stroke'\n",
    "onehot_ftrs = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "num_ftrs = ['age', 'avg_glucose_level']\n",
    "bin_ftrs = ['hypertension', 'heart_disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_train, X_CV, X_test, random_state):\n",
    "    onehot_enc = OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore')\n",
    "    cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "    onehot_encoded = onehot_enc.fit_transform(cat_imputer.fit_transform(X_train[onehot_ftrs]))\n",
    "    X_train_oh = pd.DataFrame(onehot_encoded, columns=onehot_enc.get_feature_names())\n",
    "    X_CV_oh = onehot_enc.transform(cat_imputer.transform(X_CV[onehot_ftrs]))\n",
    "    X_CV_oh = pd.DataFrame(X_CV_oh, columns=onehot_enc.get_feature_names())\n",
    "    X_test_oh = onehot_enc.transform(cat_imputer.transform(X_test[onehot_ftrs]))\n",
    "    X_test_oh = pd.DataFrame(X_test_oh, columns=onehot_enc.get_feature_names())\n",
    "                \n",
    "    scaler = MinMaxScaler()\n",
    "    iter_imputer = IterativeImputer(estimator = RandomForestRegressor(n_estimators=100), \n",
    "                                    random_state = random_state)\n",
    "    mm_scaled = scaler.fit_transform(iter_imputer.fit_transform(X_train[num_ftrs]))\n",
    "    X_train_num = pd.DataFrame(mm_scaled, columns=num_ftrs)\n",
    "    X_CV_num = scaler.transform(iter_imputer.transform(X_CV[num_ftrs]))\n",
    "    X_CV_num = pd.DataFrame(X_CV_num, columns=num_ftrs)\n",
    "    X_test_num = scaler.transform(iter_imputer.transform(X_test[num_ftrs]))\n",
    "    X_test_num = pd.DataFrame(X_test_num, columns=num_ftrs)\n",
    "        \n",
    "    X_train_bin = X_train[bin_ftrs]\n",
    "    X_CV_bin = X_CV[bin_ftrs]\n",
    "    X_test_bin = X_test[bin_ftrs]\n",
    "    X_train_bin.reset_index(drop=True, inplace=True)\n",
    "    X_CV_bin.reset_index(drop=True, inplace=True)\n",
    "    X_test_bin.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    X_train_ = pd.concat([X_train_bin, X_train_oh, X_train_num], axis=1)\n",
    "    X_CV_ = pd.concat([X_CV_bin, X_CV_oh, X_CV_num], axis=1)\n",
    "    X_test_ = pd.concat([X_test_bin, X_test_oh, X_test_num], axis=1) \n",
    "    \n",
    "    return X_train_, X_CV_, X_test_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metric baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision base line is 0.01804147465437788.\n",
      "recall base line is 1.\n",
      "f1 score base line is 0.03544349636738112.\n"
     ]
    }
   ],
   "source": [
    "# precision\n",
    "base_precision = len(df[df[label]==1])/df.shape[0]\n",
    "base_recall = 1\n",
    "base_f1 = 2*base_precision*base_recall/(base_precision+base_recall)\n",
    "print('precision base line is {}.'.format(base_precision))\n",
    "print('recall base line is {}.'.format(base_recall))\n",
    "print('f1 score base line is {}.'.format(base_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[label]\n",
    "X = df.drop(columns=[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state = 0:\n",
      "Best alpha for f1 score is 42.81332398719387\n",
      "random state = 42:\n",
      "Best alpha for f1 score is 42.81332398719387\n",
      "random state = 84:\n",
      "Best alpha for f1 score is 42.81332398719387\n",
      "random state = 126:\n",
      "Best alpha for f1 score is 42.81332398719387\n",
      "random state = 168:\n",
      "Best alpha for f1 score is 42.81332398719387\n",
      "test recall score: 0.036 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "def ML_pipeline_kfold_logistic(X, y, random_state, n_folds):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    f1_scores = []\n",
    "    best_alphas_f1 = []\n",
    "\n",
    "    for train_index, CV_index in kf.split(X_other, y_other):\n",
    "        X_train, X_CV = X_other.iloc[train_index.tolist()], X_other.iloc[CV_index.tolist()]\n",
    "        y_train, y_CV = y_other.iloc[train_index.tolist()], y_other.iloc[CV_index.tolist()]\n",
    "\n",
    "        X_train_, X_CV_, X_test_ = preprocess(X_train, X_CV, X_test, random_state)\n",
    "        \n",
    "        alpha = np.logspace(-5, 2, num=20)\n",
    "        clfs = []\n",
    "        thresholds = []\n",
    "        CV_score_f1 = []\n",
    "        \n",
    "        for a in alpha:\n",
    "            clf = LogisticRegression(penalty='l1', C=1/a, max_iter=10000, solver='saga',\n",
    "                                    multi_class='auto')\n",
    "            clf.fit(X_train_, y_train)\n",
    "            \n",
    "            y_train_prob = clf.predict_proba(X_train_)\n",
    "            thres = min([prob2 for [prob1, prob2] in y_train_prob])\n",
    "            y_CV_prob = clf.predict_proba(X_CV_)\n",
    "            y_CV_prob = [prob2 for [prob1, prob2] in y_CV_prob]\n",
    "            y_CV_pred = [1 if prob>thres else 0 for prob in y_CV_prob]\n",
    "            \n",
    "            CV_score_f1.append(f1_score(y_CV, y_CV_pred))\n",
    "            thresholds.append(thres)\n",
    "            clfs.append(clf)\n",
    "        \n",
    "        best_alpha_f1 = alpha[np.argmax(CV_score_f1)]\n",
    "        best_alphas_f1.append(best_alpha_f1)\n",
    "        clf = clfs[np.argmax(CV_score_f1)]\n",
    "        thres = thresholds[np.argmax(CV_score_f1)]\n",
    "        y_test_prob = clf.predict_proba(X_test_)\n",
    "        y_test_prob = [prob2 for [prob1, prob2] in y_test_prob]\n",
    "        y_test_pred = [1 if prob>thres else 0 for prob in y_test_prob]\n",
    "        f1_scores.append(f1_score(y_test,y_test_pred))\n",
    "\n",
    "    best_a_f1 = best_alphas_f1[np.argmax(f1_scores)]\n",
    "    return best_a_f1, f1_scores\n",
    "\n",
    "f1_scores_l = []\n",
    "\n",
    "for i in range(5):\n",
    "    random_state = 42*i\n",
    "    best_a_f1, f1_scores = ML_pipeline_kfold_logistic(X, y, random_state, 5)\n",
    "\n",
    "    f1_scores_l.append(f1_scores)\n",
    "    print('random state = {}:'.format(random_state))\n",
    "    print('Best alpha for f1 score is {}'.format(best_a_f1))\n",
    "\n",
    "mean_f1_l = np.mean(f1_scores_l)\n",
    "std_f1_l = np.std(f1_scores_l)\n",
    "print('test recall score:', np.around(mean_f1_l,3), '+/-', np.around(std_f1_l,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_paras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-981c9c7a5726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mbest_para_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mML_pipeline_kfold_random_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mf1_scores_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'random state = {}:.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-981c9c7a5726>\u001b[0m in \u001b[0;36mML_pipeline_kfold_random_forest\u001b[0;34m(X, y, random_state, n_folds)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mf1_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mbest_para_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_paras\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_para_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_paras' is not defined"
     ]
    }
   ],
   "source": [
    "def ML_pipeline_kfold_random_forest(X, y, random_state, n_folds):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, stratify=y,\n",
    "                                                        random_state = random_state)\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    f1_scores = []\n",
    "    best_paras_f1 = []\n",
    "\n",
    "    for train_index, CV_index in kf.split(X_other, y_other):\n",
    "        X_train, X_CV = X_other.iloc[train_index.tolist()], X_other.iloc[CV_index.tolist()]\n",
    "        y_train, y_CV = y_other.iloc[train_index.tolist()], y_other.iloc[CV_index.tolist()]\n",
    "        \n",
    "        X_train_, X_CV_, X_test_ = preprocess(X_train, X_CV, X_test, random_state)\n",
    "        \n",
    "        paras = [(d, s) for d in range(1, 10) for s in range(3, 15)]\n",
    "        clfs = []\n",
    "        thresholds = []\n",
    "        CV_score_f1 = []\n",
    "\n",
    "        for d, s in paras:\n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=random_state, \n",
    "                                 max_depth=d, min_samples_split=s)\n",
    "            clf.fit(X_train_, y_train)\n",
    "            y_train_prob = clf.predict_proba(X_train_)\n",
    "            thres = min([prob2 for [prob1, prob2] in y_train_prob])\n",
    "            y_CV_prob = clf.predict_proba(X_CV_)\n",
    "            y_CV_prob = [prob2 for [prob1, prob2] in y_CV_prob]\n",
    "            y_CV_pred = [1 if prob>thres else 0 for prob in y_CV_prob]\n",
    "\n",
    "            CV_score_f1.append(f1_score(y_CV, y_CV_pred))\n",
    "            thresholds.append(thres)\n",
    "            clfs.append(clf)\n",
    "        \n",
    "        best_d_f1 = paras[np.argmax(CV_score_f1)][0]\n",
    "        best_s_f1 = paras[np.argmax(CV_score_f1)][1]\n",
    "        best_paras_f1.append((best_d_f1, best_s_f1))\n",
    "        clf = clfs[np.argmax(CV_score_f1)]\n",
    "        thres = thresholds[np.argmax(CV_score_f1)]\n",
    "        y_test_prob = clf.predict_proba(X_test_)\n",
    "        y_test_prob = [prob2 for [prob1, prob2] in y_test_prob]\n",
    "        y_test_pred = [1 if prob>thres else 0 for prob in y_test_prob]\n",
    "        f1_scores.append(f1_score(y_test,y_test_pred))\n",
    "  \n",
    "    best_para_f1 = best_paras_f1[np.argmax(f1_scores)]\n",
    "    return best_para_f1, f1_scores  \n",
    "\n",
    "f1_scores_rf = []\n",
    "for i in range(8):\n",
    "    random_state = 42*i\n",
    "    best_para_f1, f1_scores = ML_pipeline_kfold_random_forest(X, y, random_state, 5)\n",
    "    f1_scores_rf.append(f1_scores)\n",
    "    print('random state = {}:.'.format(random_state))\n",
    "    print('Best max_depth is {} and best min_samples_split is {}.'.format(best_para_f1[0], best_para_f1[1]))\n",
    "    \n",
    "mean_f1_rf = np.mean(f1_scores_rf)\n",
    "std_f1_rf = np.std(f1_scores_rf)\n",
    "print('test f1 score:', np.around(mean_f1_rf,3), '+/-', np.around(std_f1_rf,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/stroke.csv')\n",
    "df['smoking'].fillna(value='missing', inplace=True)\n",
    "\n",
    "df['stroke'].replace(to_replace=0, value='not stroke', inplace=True)\n",
    "df['stroke'].replace(to_replace=1, value='stroke', inplace=True)\n",
    "\n",
    "df['hypertension'].replace(to_replace=0, value='No', inplace=True)\n",
    "df['hypertension'].replace(to_replace=1, value='Yes', inplace=True)\n",
    "\n",
    "df['heart_disease'].replace(to_replace=0, value='No', inplace=True)\n",
    "df['heart_disease'].replace(to_replace=1, value='Yes', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Feature -- age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['stroke'].unique()\n",
    "bin_range = (df['age'].min(), df['age'].max())\n",
    "\n",
    "for c in categories:\n",
    "    plt.hist(df[df['stroke']==c]['age'], alpha=0.5, label=c, range=bin_range, bins=20, density=True)\n",
    "plt.legend()\n",
    "plt.ylabel('pdf')\n",
    "plt.xlabel('age')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/age_hist.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [df[df['stroke']=='not stroke']['age'].values,\n",
    "           df[df['stroke']=='stroke']['age'].values]\n",
    "\n",
    "plt.violinplot(dataset = dataset)\n",
    "plt.xticks([1,2], ['not stroke','stroke'])\n",
    "plt.ylabel('age')\n",
    "plt.savefig('../figures/age_violin.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Feature -- avg_glucose_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['stroke'].unique()\n",
    "bin_range = (df['avg_glucose_level'].min(), df['avg_glucose_level'].max())\n",
    "\n",
    "for c in categories:\n",
    "    plt.hist(df[df['stroke']==c]['avg_glucose_level'], alpha=0.5, label=c, range=bin_range, bins=20, density=True)\n",
    "plt.legend()\n",
    "plt.ylabel('pdf')\n",
    "plt.xlabel('avg_glucose_level')\n",
    "plt.axvline(x=70, color='r')\n",
    "plt.axvline(x=126, color='r')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/avg_glucose_level_hist.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [df[df['stroke']=='not stroke']['avg_glucose_level'].values,\n",
    "           df[df['stroke']=='stroke']['avg_glucose_level'].values]\n",
    "\n",
    "plt.violinplot(dataset = dataset)\n",
    "plt.xticks([1,2], ['not stroke', 'stroke'])\n",
    "plt.ylabel('avg_glucose_level')\n",
    "plt.savefig('../figures/avg_glucose_level_violin.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Feature -- bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['stroke'].unique()\n",
    "bin_range = (df['bmi'].min(), df['bmi'].max())\n",
    "\n",
    "for c in categories:\n",
    "    plt.hist(df[df['stroke']==c]['bmi'], alpha=0.5,\n",
    "             label=c, range=bin_range, bins=20, density=True)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('pdf')\n",
    "plt.xlabel('bmi')\n",
    "plt.axvline(x=18.5, color='r')\n",
    "plt.axvline(x=25, color='r')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/bmi_hist.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature -- hypertension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = df.groupby(['hypertension', 'stroke']).size().unstack()\n",
    "count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1), axis=0)\n",
    "count_matrix_norm.plot(kind='bar', stacked=True, color=('steelblue', 'powderblue'))\n",
    "plt.ylabel('fraction of people in group')\n",
    "plt.ylim(0.93,1)\n",
    "plt.savefig('../figures/hypertension_bar.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = df['hypertension'], y = df['age'], hue = df['stroke'], palette = 'Blues')\n",
    "plt.savefig('../figures/hyper_age_stroke')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature -- heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = df.groupby(['heart_disease', 'stroke']).size().unstack()\n",
    "count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1), axis=0)\n",
    "count_matrix_norm.plot(kind='bar', stacked=True, color=('steelblue', 'powderblue'))\n",
    "plt.ylabel('fraction of people in group')\n",
    "plt.ylim(0.9,1)\n",
    "plt.savefig('../figures/heart_disease_bar.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = df['heart_disease'], y = df['age'], hue = df['stroke'], palette = 'Blues')\n",
    "plt.savefig('../figures/heart_age_stroke')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature -- gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = df.groupby(['gender', 'stroke']).size().unstack()\n",
    "count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1), axis=0)\n",
    "count_matrix_norm.plot(kind='bar', stacked=True, color=('steelblue', 'powderblue'))\n",
    "plt.ylabel('fraction of people in group')\n",
    "plt.ylim(0.97, 1)\n",
    "plt.savefig('../figures/gender_bar.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature -- work_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = df.groupby(['work_type', 'stroke']).size().unstack()\n",
    "count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1), axis=0)\n",
    "count_matrix_norm.plot(kind='bar', stacked=True, color=('steelblue', 'powderblue'))\n",
    "plt.ylabel('fraction of people in group')\n",
    "plt.ylim(0.95, 1)\n",
    "plt.savefig('../figures/work_type_bar.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature -- smoking_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = df.groupby(['smoking_status', 'stroke']).size().unstack()\n",
    "count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1), axis=0)\n",
    "count_matrix_norm.plot(kind='bar', stacked=True, color=('steelblue', 'powderblue'))\n",
    "plt.ylabel('fraction of people in group')\n",
    "plt.ylim(0.96, 1)\n",
    "plt.savefig('../figures/smoking_status_bar.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = df['smoking_status'], y = df['age'], hue = df['stroke'], palette = 'Blues')\n",
    "plt.savefig('../figures/smoking_age_stroke')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature -- Residence_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = df.groupby(['Residence_type', 'stroke']).size().unstack()\n",
    "count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1), axis=0)\n",
    "count_matrix_norm.plot(kind='bar', stacked=True, color=('steelblue', 'powderblue'))\n",
    "plt.ylabel('fraction of people in group')\n",
    "plt.ylim(0.96, 1)\n",
    "plt.savefig('../figures/Residence_type_bar.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature -- ever_married"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = df.groupby(['ever_married', 'stroke']).size().unstack()\n",
    "count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1), axis=0)\n",
    "count_matrix_norm.plot(kind='bar', stacked=True, color=('steelblue', 'powderblue'))\n",
    "plt.ylabel('fraction of people in group')\n",
    "plt.ylim(0.97, 1)\n",
    "plt.savefig('../figures/ever_married_bar.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = df['ever_married'], y = df['age'], hue = df['stroke'], palette = 'Blues')\n",
    "plt.savefig('../figures/ever_age_stroke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
